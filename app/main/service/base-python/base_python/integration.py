"""
MIT License

Copyright (c) 2020 Airbyte

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
"""
import argparse
import json
import os
import pkgutil
from abc import ABC, abstractmethod
from collections import defaultdict
from typing import Dict, Generator, Iterable, Mapping

from airbyte_protocol import (
    AirbyteCatalog,
    AirbyteConnectionStatus,
    AirbyteMessage,
    ConfiguredAirbyteCatalog,
    ConnectorSpecification,
    Type,
)

from .logger import AirbyteLogger


class AirbyteSpec(object):
    @staticmethod
    def from_file(file: str):
        with open(file) as file:
            spec_text = file.read()
        return AirbyteSpec(spec_text)

    def __init__(self, spec_string):
        self.spec_string = spec_string


class Integration(ABC):

    # can be overridden to change an input config
    def configure(self, config: json, temp_dir: str) -> json:
        """
        Persist config in temporary directory to run the Source job
        """
        config_path = os.path.join(temp_dir, "config.json")
        self.write_config(config, config_path)
        return config

    @staticmethod
    def read_config(config_path: str) -> json:
        with open(config_path, "r") as file:
            contents = file.read()
        return json.loads(contents)

    @staticmethod
    def write_config(config: json, config_path: str):
        with open(config_path, "w") as fh:
            fh.write(json.dumps(config))

    # can be overridden to change an input catalog
    def read_catalog(self, catalog_path: str) -> ConfiguredAirbyteCatalog:
        return ConfiguredAirbyteCatalog.parse_obj(self.read_config(catalog_path))

    def spec(self, logger: AirbyteLogger) -> ConnectorSpecification:
        """
        Returns the spec for this integration. The spec is a JSON-Schema object describing the required configurations (e.g: username and password)
        required to run this integration.
        """
        raw_spec = pkgutil.get_data(
            self.__class__.__module__.split(".")[0], "spec.json"
        )
        return ConnectorSpecification.parse_obj(json.loads(raw_spec))

    @abstractmethod
    def check(
        self, logger: AirbyteLogger, config: Mapping[str, any]
    ) -> AirbyteConnectionStatus:
        """
        Tests if the input configuration can be used to successfully connect to the integration e.g: if a provided Stripe API token can be used to connect
        to the Stripe API.
        """
        raise Exception("Not Implemented")


class Source(Integration):
    # can be overridden to change an input state
    def read_state(self, state_path: str) -> Dict[str, any]:
        if state_path:
            state_obj = json.loads(open(state_path, "r").read())
        else:
            state_obj = {}
        state = defaultdict(dict, state_obj)
        return state

    def discover(self, logger: AirbyteLogger, config: json) -> AirbyteCatalog:
        """
        Returns an AirbyteCatalog representing the available streams and fields in this integration. For example, given valid credentials to a
        Postgres database, returns an Airbyte catalog where each postgres table is a stream, and each table column is a field.
        """
        raise Exception("Not Implemented")

    def read(
        self,
        logger: AirbyteLogger,
        config: json,
        catalog: ConfiguredAirbyteCatalog,
        state_path: Dict[str, any],
    ) -> Generator[AirbyteMessage, None, None]:
        """
        Returns a generator of the AirbyteMessages generated by reading the source with the given configuration, catalog, and state.
        """
        raise Exception("Not Implemented")


class Destination(Integration, ABC):
    logger = AirbyteLogger()

    @abstractmethod
    def write(
        self,
        logger: AirbyteLogger,
        config: Mapping[str, any],
        configured_catalog: ConfiguredAirbyteCatalog,
    ) -> Iterable[AirbyteMessage]:
        """Implement to define how the connector writes data to the destination"""

    def _run_spec(self):
        message = AirbyteMessage(type=Type.SPEC, spec=self.spec(self.logger))
        print(message.json(exclude_unset=True))

    def _run_check(self, config_path: str):
        config = self.read_config(config_path=config_path)
        check_result = self.check(self.logger, config)
        output_message = AirbyteMessage(
            type=Type.CONNECTION_STATUS, connectionStatus=check_result
        )
        print(output_message.json(exclude_unset=True))

    def _run_write(self, config_path: str, configured_catalog_path: str):
        config = self.read_config(config_path=config_path)
        catalog = self.read_catalog(catalog_path=configured_catalog_path)
        self.logger.info("Begin writing to the destination...")
        self.write(self.logger, config, catalog)
        self.logger.info("Writing complete.")

    def run(self, args):
        parent_parser = argparse.ArgumentParser(add_help=False)
        main_parser = argparse.ArgumentParser()
        subparsers = main_parser.add_subparsers(title="commands", dest="command")

        # spec
        subparsers.add_parser(
            "spec",
            help="outputs the json configuration specification",
            parents=[parent_parser],
        )

        # check
        check_parser = subparsers.add_parser(
            "check",
            help="checks the config can be used to connect",
            parents=[parent_parser],
        )
        required_check_parser = check_parser.add_argument_group(
            "required named arguments"
        )
        required_check_parser.add_argument(
            "--config",
            type=str,
            required=True,
            help="path to the json configuration file",
        )

        # write
        write_parser = subparsers.add_parser(
            "write", help="Writes data to the destination", parents=[parent_parser]
        )
        write_required = write_parser.add_argument_group("required named arguments")
        write_required.add_argument(
            "--config",
            type=str,
            required=True,
            help="path to the JSON configuration file",
        )
        write_required.add_argument(
            "--catalog",
            type=str,
            required=True,
            help="path to the configured catalog JSON file",
        )

        parsed_args = main_parser.parse_args(args)

        cmd = parsed_args.command
        if cmd == "spec":
            self._run_spec()
        elif cmd == "check":
            self._run_check(config_path=parsed_args.config)
        elif cmd == "write":
            self._run_write(
                config_path=parsed_args.config,
                configured_catalog_path=parsed_args.catalog,
            )
        elif cmd is None:
            raise Exception(f"No command entered. ")
        else:
            raise Exception(f"Unrecognized command: {cmd}")
